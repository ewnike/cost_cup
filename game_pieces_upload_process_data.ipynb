{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Upload and Process Data\n",
    "\n",
    "In this part of the project, we will use the `main.py` script to set up the database and run scripts that read NHL data from AWS S3 buckets, process it, and insert it into the database.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Running the `main.py` Script](#running-the-mainpy-script)\n",
    "3. [Understanding the Logging](#understanding-the-logging)\n",
    "4. [Verifying the Processed Data](#verifying-the-processed-data)\n",
    "5. [Conclusion](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook will guide you through running the `main.py` script, which automates the process of downloading NHL data from AWS S3 buckets, processing it, and inserting it into the `hockey_stats` database. We will also review the log file generated during this process to ensure everything has executed correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running the `main.py` Script\n",
    "\n",
    "The `main.py` script is the entry point for the data processing workflow. It runs a series of Python scripts that handle different parts of the data processing pipeline. These scripts are responsible for downloading data, processing it, and inserting it into the database.\n",
    "\n",
    "Below is the code from `main.py`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import subprocess\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"data_processing.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    ")\n",
    "\n",
    "\n",
    "def run_script(script_name):\n",
    "    \"\"\"Code to kickoff downloading data from AWS S3 buckets and\n",
    "    inserting data into datatables in the hockey_stats database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"python\", script_name], capture_output=True, text=True, check=True\n",
    "        )\n",
    "        logging.info(f\"Output of {script_name}:\\n{result.stdout}\")\n",
    "        if result.stderr:\n",
    "            logging.error(f\"Errors in {script_name}:\\n{result.stderr}\")\n",
    "        print(result.stdout)\n",
    "        print(result.stderr)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        # This will catch the error if the subprocess fails and check=True is set\n",
    "        logging.error(f\"Script {script_name} failed with error: {e.stderr}\")\n",
    "        print(f\"Script {script_name} failed with error: {e.stderr}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to run {script_name}: {e}\")\n",
    "        print(f\"Failed to run {script_name}: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"The main event\"\"\"\n",
    "    scripts = [\n",
    "        \"game_processor.py\",\n",
    "        \"game_shifts_processor.py\",\n",
    "        \"game_skater_stats_processor.py\",\n",
    "        \"game_plays_processor.py\",\n",
    "        \"player_info_processor.py\",\n",
    "    ]\n",
    "\n",
    "    for script in scripts:\n",
    "        run_script(script)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this script in Jupyter, we use the `!` command to execute the script in the notebook environment. This will simulate running the script in the terminal.\n",
    "\n",
    "# Running the main.py script\n",
    "!python main.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding the Logging\n",
    "\n",
    "As `main.py` runs, it logs detailed information to a file named `data_processing.log`. This log file is crucial for debugging and understanding what happened during the execution of the scripts.\n",
    "\n",
    "Let's take a look at the contents of `data_processing.log` to ensure everything ran smoothly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the contents of the data_processing.log file\n",
    "with open(\"data_processing.log\", \"r\") as log_file:\n",
    "    log_content = log_file.read()\n",
    "\n",
    "print(log_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Log\n",
    "\n",
    "Check for any ERROR messages in the log file. If errors are present, they indicate issues that need to be addressed before moving forward. If everything looks good, the scripts have successfully processed and inserted the data into the database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verifying the Processed Data\n",
    "\n",
    "After running the `main.py` script, it's important to verify that the data has been correctly processed and inserted into the database. We can do this by querying the database and checking the contents of the tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create a database connection\n",
    "engine = create_engine(\"your_database_connection_string\")\n",
    "\n",
    "# Example query to check the data in one of the tables\n",
    "df = pd.read_sql(\"SELECT * FROM game_skater_stats LIMIT 5;\", engine)\n",
    "\n",
    "# Display the data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "In this notebook, we successfully ran the `main.py` script, reviewed the logs, and verified that the data was processed and inserted into the database correctly. This sets the stage for more advanced analysis in subsequent parts of the project.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cost_cup_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
