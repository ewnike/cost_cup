{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Inserting Corsi Statistics for Hockey Analytics\n",
    "\n",
    "This notebook demonstrates how to load hockey game data, calculate Corsi statistics, and prepare the data for further analysis or insertion into a database. We will use the following scripts:\n",
    "- `load_data.py` to load the necessary data from the database.\n",
    "- `corsi_make_stats.py` to calculate the Corsi statistics and save them for future use.\n",
    "\n",
    "### Author\n",
    "Eric Winiecke\n",
    "\n",
    "### Date\n",
    "August 11, 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import (\n",
    "    BigInteger,\n",
    "    Column,\n",
    "    Float,\n",
    "    Integer,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    create_engine,\n",
    ")\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define functions from load_data.py for loading data\n",
    "def get_env_vars():\n",
    "    \"\"\"Assemble credentials for database connection.\"\"\"\n",
    "    env_vars = {\n",
    "        \"DATABASE_TYPE\": os.getenv(\"DATABASE_TYPE\"),\n",
    "        \"DBAPI\": os.getenv(\"DBAPI\"),\n",
    "        \"ENDPOINT\": os.getenv(\"ENDPOINT\"),\n",
    "        \"USER\": os.getenv(\"USER\"),\n",
    "        \"PASSWORD\": os.getenv(\"PASSWORD\"),\n",
    "        \"PORT\": int(os.getenv(\"PORT\", 5432)),\n",
    "        \"DATABASE\": os.getenv(\"DATABASE\"),\n",
    "    }\n",
    "    return env_vars\n",
    "\n",
    "def get_db_engine(env_vars):\n",
    "    \"\"\"Create connection string to database.\"\"\"\n",
    "    connection_string = (\n",
    "        f\"{env_vars['DATABASE_TYPE']}+{env_vars['DBAPI']}://\"\n",
    "        f\"{env_vars['USER']}:{env_vars['PASSWORD']}@\"\n",
    "        f\"{env_vars['ENDPOINT']}:{env_vars['PORT']}/\"\n",
    "        f\"{env_vars['DATABASE']}\"\n",
    "    )\n",
    "    return create_engine(connection_string)\n",
    "\n",
    "def load_data(env_vars):\n",
    "    \"\"\"Connect to database and load data into DataFrames.\"\"\"\n",
    "    engine = get_db_engine(env_vars)\n",
    "\n",
    "    queries = {\n",
    "        \"game_skater_stats\": \"SELECT * FROM game_skater_stats\",\n",
    "        \"game_plays\": \"SELECT * FROM game_plays\",\n",
    "        \"game_shifts\": \"SELECT * FROM game_shifts\",\n",
    "        \"game\": \"SELECT * FROM game\",\n",
    "    }\n",
    "\n",
    "    df = {}\n",
    "    for name, query in queries.items():\n",
    "        df[name] = pd.read_sql(query, engine)\n",
    "        print(f\"{name}:\")\n",
    "        display(df[name].head())  # Display first few rows for each DataFrame\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load environment variables and data\n",
    "env_vars = get_env_vars()\n",
    "df_master = load_data(env_vars)\n",
    "print(\"Data loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculating Corsi Statistics\n",
    "\n",
    "After loading the data, we will process it to calculate Corsi statistics, which are advanced metrics used in hockey analytics to measure shot attempts and puck possession.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_num_players`\n",
    "This function tracks the number of players on the ice at specific times, which is crucial for assigning the correct shift stats per player. It processes the shift data to calculate when players start and stop their shifts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_players(shift_df):\n",
    "    shifts_melted = pd.melt(\n",
    "        shift_df,\n",
    "        id_vars=[\"game_id\", \"player_id\"],\n",
    "        value_vars=[\"shift_start\", \"shift_end\"],\n",
    "    )\n",
    "    shifts_melted = shifts_melted.sort_values(\"value\", ignore_index=True)\n",
    "    shifts_melted[\"change\"] = (\n",
    "        2 * (shifts_melted[\"variable\"] == \"shift_start\").astype(int) - 1\n",
    "    )\n",
    "    shifts_melted[\"num_players\"] = shifts_melted[\"change\"].cumsum()\n",
    "    df_num_players = shifts_melted.groupby(\"value\")[\"num_players\"].last().reset_index()\n",
    "    mask = df_num_players[\"num_players\"].shift() != df_num_players[\"num_players\"]\n",
    "    df_num_players = df_num_players.loc[mask].reset_index(drop=True)\n",
    "\n",
    "    return df_num_players\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_penalty_exclude_times`\n",
    "This function identifies periods during a game when there is an imbalance in the number of players on the ice, usually due to penalties. It processes the shifts and skater stats data to find these periods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_penalty_exclude_times(game_shifts, game_skater_stats):\n",
    "    game_shifts = pd.merge(\n",
    "        game_shifts, game_skater_stats[[\"player_id\", \"team_id\"]], on=\"player_id\"\n",
    "    )\n",
    "    if len(game_shifts) == 0:\n",
    "        print(\"FIRE in the HOUSE\")\n",
    "        print(game_shifts)\n",
    "\n",
    "    team_1 = game_shifts.loc[0, \"team_id\"]\n",
    "    mask = game_shifts[\"team_id\"] == team_1\n",
    "\n",
    "    shifts_1 = game_shifts[mask]\n",
    "    shifts_2 = game_shifts[~mask]\n",
    "\n",
    "    df_num_players_1 = get_num_players(shifts_1)\n",
    "    df_num_players_2 = get_num_players(shifts_2)\n",
    "\n",
    "    df_num_players_1 = df_num_players_1.rename(\n",
    "        columns={\"value\": \"time\", \"num_players\": \"team_1\"}\n",
    "    )\n",
    "    df_num_players_1[\"team_2\"] = np.nan\n",
    "    df_num_players_2 = df_num_players_2.rename(\n",
    "        columns={\"value\": \"time\", \"num_players\": \"team_2\"}\n",
    "    )\n",
    "    df_num_players_2[\"team_1\"] = np.nan\n",
    "\n",
    "    df_exclude = pd.concat([df_num_players_1, df_num_players_2])\n",
    "    df_exclude = df_exclude.sort_values(\"time\", ignore_index=True)\n",
    "    df_exclude = df_exclude.ffill()\n",
    "\n",
    "    mask = df_exclude[\"time\"].shift(-1) != df_exclude[\"time\"]\n",
    "    df_exclude = df_exclude[mask]\n",
    "\n",
    "    diff = df_exclude[\"team_1\"] != df_exclude[\"team_2\"]\n",
    "    missing = (df_exclude[\"team_1\"] < 5) | (df_exclude[\"team_2\"] < 5)\n",
    "    df_exclude[\"exclude\"] = diff & missing\n",
    "    df_exclude = df_exclude.reset_index(drop=True)\n",
    "\n",
    "    return df_exclude\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `organize_by_season`\n",
    "This function processes the hockey data for multiple seasons and computes Corsi metrics. It filters, merges, and manipulates data for each season to prepare it for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_by_season(seasons, df):\n",
    "    df_orig = df\n",
    "    nhl_dfs = []\n",
    "    for season in seasons:\n",
    "        print(f\"Processing season: {season}\")\n",
    "        df = df_orig.copy()\n",
    "        df[\"game\"] = df[\"game\"].query(f\"season == {season}\")\n",
    "\n",
    "        print(f\"Games for season {season}:\")\n",
    "        print(df[\"game\"].head())\n",
    "\n",
    "        for name in [\"game_skater_stats\", \"game_plays\", \"game_shifts\"]:\n",
    "            df[name] = pd.merge(\n",
    "                df[name], df[\"game\"][[\"game_id\"]], on=\"game_id\"\n",
    "            ).drop_duplicates()\n",
    "\n",
    "            for key, val in df.items():\n",
    "                print(f\"{key:>25}: {len(val)}\")\n",
    "\n",
    "        print(\"game_plays before filtering events:\")\n",
    "        print(df[\"game_plays\"].head())\n",
    "\n",
    "        cols = [\"play_id\", \"game_id\", \"team_id_for\", \"event\", \"time\"]\n",
    "        events = [\"Shot\", \"Blocked Shot\", \"Missed Shot\", \"Goal\"]\n",
    "        df[\"game_plays\"] = df[\"game_plays\"].loc[df[\"game_plays\"][\"event\"].isin(events)]\n",
    "        df[\"game_plays\"][\"time\"] = (\n",
    "            df[\"game_plays\"][\"periodTime\"] + (df[\"game_plays\"][\"period\"] - 1) * 1200\n",
    "        )\n",
    "        df[\"game_plays\"] = df[\"game_plays\"][cols]\n",
    "\n",
    "        print(f\"reduced game_plays num rows: {len(df['game_plays'])}\")\n",
    "        print(df[\"game_plays\"].head())\n",
    "\n",
    "        print(\"game_skater_stats before merging with game_shifts:\")\n",
    "        print(df[\"game_skater_stats\"].head())\n",
    "        print(\"game_shifts before merging with game_skater_stats:\")\n",
    "        print(df[\"game_shifts\"].head())\n",
    "\n",
    "        df[\"game_skater_stats\"] = pd.merge(\n",
    "            df[\"game_skater_stats\"], df[\"game_shifts\"][[\"game_id\"]], on=\"game_id\"\n",
    "        ).drop_duplicates(ignore_index=True)\n",
    "\n",
    "        print(\"Merged game_skater_stats:\")\n",
    "        print(df[\"game_skater_stats\"].head())\n",
    "\n",
    "        df_corsi = df[\"game_skater_stats\"].sort_values(\n",
    "            [\"game_id\", \"player_id\"], ignore_index=True\n",
    "        )[[\"game_id\", \"player_id\", \"team_id\"]]\n",
    "\n",
    "        print(f\"df_corsi for season {season}:\")\n",
    "        print(df_corsi.head())\n",
    "\n",
    "        print(f\"Calling create_corsi_stats for season: {season}\")\n",
    "        nhl_dfs.append([season, create_corsi_stats(df_corsi, df)])\n",
    "        print(f\"Completed create_corsi_stats for season: {season}\")\n",
    "\n",
    "    return nhl_dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `create_corsi_stats`\n",
    "This function calculates Corsi statistics for individual players using a DataFrame that contains player and game information. Corsi is a key metric used to measure puck possession in hockey.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corsi_stats(df_corsi, df):\n",
    "    df_corsi[[\"corsi_for\", \"corsi_against\", \"corsi\"]] = np.nan\n",
    "\n",
    "    game_id_prev = None\n",
    "    shifts_game, plays_game = None, None\n",
    "    t1 = perf_counter()\n",
    "\n",
    "    for i, row in df_corsi.iterrows():\n",
    "        game_id, player_id, team_id = row.iloc[:3]\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"{i:>6}/{len(df_corsi)}, {perf_counter() - t1:.2f} s\")\n",
    "\n",
    "        if pd.isna(game_id):\n",
    "            print(f\"Skipping row with NaN game_id: {row}\")\n",
    "            continue\n",
    "\n",
    "        if game_id != game_id_prev:\n",
    "            game_id_prev = game_id\n",
    "            shifts_game = df[\"game_shifts\"].query(f\"game_id == {game_id}\")\n",
    "            plays_game = df[\"game_plays\"].query(f\"game_id == {game_id}\")\n",
    "\n",
    "            gss = df[\"game_skater_stats\"].query(f\"game_id == {game_id}\")\n",
    "            if 0 in [len(shifts_game), len(gss)]:\n",
    "                print(f\"game_id: {game_id}\")\n",
    "                print(\"Empty DF before Merge.\")\n",
    "                continue\n",
    "\n",
    "            df_num_players = get_penalty_exclude_times(shifts_game, gss).reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "            idx = df_num_players[\"time\"].searchsorted(plays_game[\"time\"]) - 1\n",
    "            idx[idx < 0] = 0\n",
    "            mask = df_num_players[\"exclude\"][idx]\n",
    "            mask = mask.reset_index(drop=True).to_numpy()\n",
    "            plays_game = plays_game.loc[~mask]\n",
    "\n",
    "        shifts_player = shifts_game.query(f\"player_id == {player_id}\")\n",
    "        mask = (\n",
    "            shifts_player[\"shift_start\"].searchsorted(plays_game[\"time\"])\n",
    "            - shifts_player[\"shift_end\"].searchsorted(plays_game[\"time\"])\n",
    "        ).astype(bool)\n",
    "\n",
    "        plays_player = plays_game[mask]\n",
    "\n",
    "        corsi_for = (plays_player[\"team_id_for\"] == team_id).sum()\n",
    "        corsi_against = len(plays_player) - corsi_for\n",
    "        corsi = corsi_for - corsi_against\n",
    "        df_corsi.iloc[i, 3:] = [corsi_for, corsi_against, corsi]\n",
    "\n",
    "    df_corsi[\"CF_Percent\"] = df_corsi[\"corsi_for\"] / (\n",
    "        df_corsi[\"corsi_for\"] + df_corsi[\"corsi_against\"]\n",
    "    )\n",
    "\n",
    "    print(df_corsi.head())\n",
    "\n",
    "    if game_id_prev is not None:\n",
    "        print(f\"Processed Corsi stats for game {game_id_prev}\")\n",
    "\n",
    "    return df_corsi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `write_csv``\n",
    "This function saves the processed Corsi data to CSV files. Each file is named according to the season it corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(dfs):\n",
    "    relative_directory = \"corsi_stats\"\n",
    "\n",
    "    if not os.path.exists(relative_directory):\n",
    "        os.makedirs(relative_directory)\n",
    "\n",
    "    for df in dfs:\n",
    "        file_path = f\"{relative_directory}/corsi_{df[0]}.csv\"\n",
    "        df[1].to_csv(file_path, index=False)\n",
    "        print(f\"Written to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `calculate_and_save_corsi_stats`\n",
    "This high-level function orchestrates the entire process, from loading data to calculating Corsi stats and saving the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_save_corsi_stats():\n",
    "    env_vars = get_env_vars()\n",
    "    df_master = load_data(env_vars)\n",
    "    print(\"Data loaded successfully\")\n",
    "\n",
    "    for name, df in df_master.items():\n",
    "        print(f\"{name}:\")\n",
    "        print(df.head())\n",
    "\n",
    "    seasons = [20152016, 20162017, 20172018]\n",
    "    nhl_dfs = organize_by_season(seasons, df_master)\n",
    "    print(\"Data organized by season\")\n",
    "\n",
    "    write_csv(nhl_dfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inserting Corsi Statistics into Database\n",
    "\n",
    "Finally, we insert the saved Corsi statistics from the CSV files into the appropriate tables in the `hockey_stats` database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database insertion functions from August 11, 2024 code\n",
    "\n",
    "def create_corsi_table(metadata, table_name):\n",
    "    \"\"\"Define table creation function to avoid repetition.\"\"\"\n",
    "    return Table(\n",
    "        table_name,\n",
    "        metadata,\n",
    "        Column(\"game_id\", BigInteger),\n",
    "        Column(\"player_id\", BigInteger),\n",
    "        Column(\"team_id\", Integer),\n",
    "        Column(\"corsi_for\", Float, nullable=True),\n",
    "        Column(\"corsi_against\", Float, nullable=True),\n",
    "        Column(\"corsi\", Float, nullable=True),\n",
    "        Column(\"CF_Percent\", Float, nullable=True),\n",
    "    )\n",
    "\n",
    "# Create tables for each season\n",
    "metadata = MetaData()\n",
    "tables = {season: create_corsi_table(metadata, f\"raw_corsi_{season}\") for season in seasons}\n",
    "metadata.create_all(engine)\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "def insert_data_from_csv(engine, table_name, file_path):\n",
    "    \"\"\"Insert data from CSV into the specified database table.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.to_sql(table_name, con=engine, if_exists=\"replace\", index=False)\n",
    "        print(f\"Data inserted successfully into {table_name}\")\n",
    "\n",
    "        # Remove the file after successful insertion\n",
    "        os.remove(file_path)\n",
    "        print(f\"File {file_path} deleted successfully.\")\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Error inserting data into {table_name}: {e}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {file_path} - {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while processing file '{file_path}': {e}\")\n",
    "\n",
    "# Define directories and mappings for insertion\n",
    "csv_files_and_mappings = [\n",
    "    (\"corsi_stats/corsi_20152016.csv\", \"raw_corsi_20152016\"),\n",
    "    (\"corsi_stats/corsi_20162017.csv\", \"raw_corsi_20162017\"),\n",
    "    (\"corsi_stats/corsi_20172018.csv\", \"raw_corsi_20172018\"),\n",
    "]\n",
    "\n",
    "# Insert data into database tables\n",
    "with Session() as session:\n",
    "    for file_path, table_name in csv_files_and_mappings:\n",
    "        insert_data_from_csv(engine, table_name, file_path)\n",
    "\n",
    "    print(\"Data inserted successfully into all tables.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution\n",
    "We run the main function to load the data, calculate the Corsi stats, and save the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    calculate_and_save_corsi_stats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "\n",
    "In this notebook, we successfully loaded hockey game data, calculated Corsi statistics, saved the results to CSV files, and inserted the data into the database tables. These steps ensure that the data is now ready for further analysis and reporting within the `hockey_stats` database.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cost_cup_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
